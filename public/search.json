[{"title":"Python","url":"/2025/03/26/Python/","content":"","categories":["服务端","Python"],"tags":["服务端，Python"]},{"title":"Shell","url":"/2025/03/26/Shell/","content":"","categories":["服务端","Shell"],"tags":["服务端","Shell"]},{"title":"Docker","url":"/2025/03/25/docker/","content":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。\n简介容器技术不仅限于docker，但是docker目前最为流行，docker容器技术的核心之一在于镜像文件。镜像文件，通俗的理解就是一个进程运行时依赖的软件文件的集装箱。\n  应用集群部署时，每台机器首先会拉取指定版本的镜像文件。安装镜像后产生了docker容器。由于所有机器的镜像文件一样，容器的软件版本故而一样。即使开发或运维中途修改了容器的软件版本，但是容器销毁时，软件的改动会随容器的销毁一起湮灭。当应用用已有的镜像文件重新部署时，生成的docker容器跟修改之前的容器完全一样。这也是Infrastructure as code思想带来的好处。\n  容器如果要升级软件版本，那就修改镜像文件。这样部署时集群内所有的机器重新拉取新的镜像，软件因此跟着一起升级。软件版本混乱的问题，到docker这里，也就得到了完美的解决。\n一个疑问：有了容器技术，生产环境为何还需要部署虚拟机？\n虚拟机能做到硬件资源的彻底隔离，docker不行。虚拟机 和 docker各取长处，最佳CP。\n安装docker解决国内Docker镜像问题由于2024年6月开始国内的大量docker镜像停服😤，Docker无法下载安装😭此仓库致力于解决国内网络原因无法使用Docker的问题使用Github Action将官网的安装脚本&#x2F;安装包定时下载到本项目Release，供国内使用官方安装包，安全可靠每天自动定时同步，保证最新作者：技术爬爬虾B站，抖音，Youtube全网同名，转载请注明作者\nLinuxsudo curl -fsSL https://get.docker.com| bash -s docker --mirror Aliyun #一键安装命令sudo curl -fsSL https://github.com/tech-shrimp/docker_installer/releases/download/latest/linux.sh| bash -s docker --mirror Aliyun# 备用命令（每天自动从官网定时同步）sudo curl -fsSL https://gitee.com/tech-shrimp/docker_installer/releases/download/latest/linux.sh| bash -s docker --mirror Aliyun# 备用2 （如果github访问不了，可以使用gitee的链接）sudo service docker start #启动Docker\n\nCentos安装dockerCentOS 7或更高版本必须启用CentOS Extras存储库。默认情况下，此存储库已启用，但如果已禁用，则需要 重新启用它。建议使用overlay2存储驱动程序。如果以前安装的老版本（Docker名称是docker或docker-engine）请先删除\ncentOSsudo yum remove docker \\docker-client \\docker-client-latest \\docker-common \\docker-latest \\docker-latest-logrotate \\docker-logrotate \\docker-engine\n上述操作只会删除docker本身，但老版本保存在&#x2F;var&#x2F;lib&#x2F;docker&#x2F;的内容，包括镜像、容器、卷和网络需要手动删除。\n安装方式1.脚本安装(多用于测试和开发环境)\ncentOScurl -fsSL https://get.docker.com -o get-docker.shsudo sh get-docker.sh\n\n2.使用仓库安装(推荐)2.1设置docker仓库\ncentOSsudo yum install -y yum-utils \\device-mapper-persistent-datalvm2sudo yum-config-manager \\--add-repo \\https://download.docker.com/linux/centos/docker-ce.repo\n2.2安装docker CE\ncentOSsudo yum install docker-ce docker-ce-cli container.io # 安装最新的Docker CE版本yum list docker-ce --showduplicates | sort -rsudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; container.io#说明：&lt;VERSION_STRING&gt;，取上图中第二列中的第一个：或第一个数字到-之间的字符串，如18.09.6、18.06.2.ce等。\n\n3.使用RPM程序包安装（适用于没有互联网接入的情况）3.1下载所需要的Docker版本下载地址： https://download.docker.com/linux/centos/7/x86_64/stable/Packages/\ncentOSsudo yum install /path/to/package.rpm# 其中/path/to/package.rpm,为你下载下来的rpm包所在位置和文件名称sudo systemctl start docker# 启动Dockersudo docker run hello-world# 验证安装是否正确\n更多信息: Centos安装docker\nUbuntu安装dockerDocker 需要在64位版本的Ubuntu上安装。此外，你还需要保证你的 Ubuntu 内核的最小版本不低于 3.10，其中3.10 小版本和更新维护版也是可以使用的。\nUbuntuuname -r 3.11.0-15-generic\n\nUbuntuwhich wget # 查看你是否安装了wgetsudo apt-get update sudo apt-get install wget # 如果wget没有安装，先升级包管理器，然后再安装它。wget -qO- https://get.docker.com/ | sh  # 获取最新版本的 Docker 安装包sudo docker run hello-world  # 验证 Docker 是否被正确的安装 # 上边的命令会下载一个测试镜像，并在容器内运行这个镜像\n更多信息: Ubuntu安装docker\nMacos安装dockerHomebrew 的 Cask 已经支持 Docker for Mac\nMacosbrew cask install docker\n在载入 Docker app 后，点击 Next，可能会询问你的 macOS 登陆密码，你输入即可。之后会弹出一个 Docker 运行的提示窗口，状态栏上也有有个小鲸鱼的图标（）。\n更多信息: Macosa安装docker\n使用dockerPull镜像方案一 转存到阿里云使用github Action将国外的Docker镜像转存到阿里云私有仓库，供国内服务器使用，免费易用支持DockerHub, gcr.io, k8s.io, ghcr.io等任意仓库支持最大40GB的大型镜像使用阿里云的官方线路，速度快项目地址: Github\n方案二 镜像站现在只有很少的国内镜像站存活不保证镜像齐全,且用且珍惜以下三个镜像站背靠较大的开源项目，优先推荐\n\n\n\n项目名称\n项目地址\n加速地址\n\n\n\n1Panel\nhttps://github.com/1Panel-dev/1Panel/\nhttps://docker.1panel.live\n\n\nDaocloud\nhttps://github.com/DaoCloud/public-image-mirror\nhttps://docker.m.daocloud.io\n\n\n耗子面板\nhttps://github.com/TheTNB/panel\nhttps://hub.rat.dev\n\n\nlinux配置镜像站\nLinuxsudo vi /etc/docker/daemon.json #创建/打开daemon文件&#123;    &quot;registry-mirrors&quot;: [        &quot;https://docker.m.daocloud.io&quot;,        &quot;https://docker.1panel.live&quot;,        &quot;https://hub.rat.dev&quot;    ]&#125;# 输入以上内容，vi按esc，输入:wq保存  nano输入ctrl+x保存退出sudo service docker restart # 重启docker\n\n方案三 离线镜像使用Github Action下载docker离线镜像 https://github.com/wukongdaily/DockerTarBuilder\n方案四 使用一键脚本dockerbash -c &quot;$(curl -sSLf https://xy.ggbond.org/xy/docker_pull.sh)&quot; -s 完整镜像名\n方案五 使用Cloudflare worker 自建镜像加速https://github.com/cmliu/CF-Workers-docker.io\n去哪里找镜像https://docker.fxxk.dedyn.io/\n更多信息: Github Action\n常用的操作命令🧱 镜像相关命令\n\n\n命令\n作用\n\n\n\ndocker images\n查看本地已有镜像\n\n\ndocker pull 镜像名[:tag]\n从远程仓库拉取镜像，例如：nginx:latest\n\n\ndocker rmi 镜像ID&#x2F;名\n删除本地镜像\n\n\ndocker build -t 镜像名 .\n通过 Dockerfile 构建镜像\n\n\ndocker tag 原名 新名\n重命名镜像标签，例如：mynginx:v1\n\n\ndocker save -o xx.tar 镜像名\n导出镜像为压缩包\n\n\ndocker load -i xx.tar\n导入压缩镜像文件\n\n\n🚀 容器运行与管理命令\n\n\n命令\n作用\n\n\n\ndocker ps\n查看正在运行的容器\n\n\ndocker ps -a\n查看所有容器（包括已停止）\n\n\ndocker run 镜像名\n启动容器，默认后台运行一次即停\n\n\ndocker run -it 镜像名 &#x2F;bin&#x2F;bash\n启动容器并进入交互模式\n\n\ndocker run -d 镜像名\n后台运行容器（detached）\n\n\ndocker run -p 宿主端口:容器端口 镜像名\n端口映射，例如：-p 8080:80\n\n\ndocker run -v 宿主路径:容器路径 镜像名\n挂载目录，例如：-v &#x2F;mydata:&#x2F;data\n\n\ndocker start&#x2F;stop&#x2F;restart 容器ID\n启动 &#x2F; 停止 &#x2F; 重启容器\n\n\ndocker exec -it 容器ID bash\n进入容器交互终端（推荐）\n\n\ndocker logs 容器ID\n查看容器日志\n\n\ndocker rm 容器ID\n删除容器\n\n\ndocker rm $(docker ps -aq)\n删除所有容器（小心使用）\n\n\n📦 数据卷（Volume）相关命令\n\n\n命令\n作用\n\n\n\ndocker volume ls\n查看所有数据卷\n\n\ndocker volume create 名字\n创建数据卷\n\n\ndocker volume inspect 名字\n查看数据卷详细信息\n\n\ndocker volume rm 名字\n删除数据卷（需先卸载）\n\n\n🌐 网络相关命令\n\n\n命令\n作用\n\n\n\ndocker network ls\n查看网络\n\n\ndocker network create 名字\n创建网络\n\n\ndocker network inspect 名字\n查看网络详情\n\n\ndocker network connect 网络名 容器名\n将容器加入某个网络\n\n\ndocker run –network 网络名 镜像\n启动时指定网络\n\n\n🛠 其他常用命令\n\n\n命令\n作用\n\n\n\ndocker info\n查看 Docker 系统信息\n\n\ndocker version\n查看 Docker 版本\n\n\ndocker system df\n查看镜像、容器、数据卷占用空间\n\n\ndocker system prune\n清理无用资源（未运行的容器、悬空镜像等）\n\n\nDocker Dockerfile一、什么是 Dockerfile？Dockerfile 是一套“食谱”，告诉 Docker 如何构建你的镜像。通过它，你可以：    •\t指定用哪个基础镜像（比如 Python、Node、Nginx）    •\t安装依赖    •\t拷贝文件    •\t执行命令    •\t设置运行服务时的默认命令\n二、Dockerfile 语法结构（超清晰版）# 1. 指定基础镜像（必须有）FROM 镜像名[:tag]# 2. 设置容器中的工作目录（可选）WORKDIR /app# 3. 拷贝文件到镜像中COPY ..# 4. 安装依赖（可多条RUN）RUN 命令# 5. 设置环境变量（可选）ENV 变量名=值# 6. 设置容器启动时执行的命令CMD [&quot;命令&quot;,&quot;参数&quot;]# 7. 设置暴露的端口（可选，用于文档提升）EXPOSE 端口号\n三、最常见的语句详解 + 示例\n\n\n指令\n示例\n说明\n\n\n\nFROM\nFROM node:18\n基础镜像\n\n\nWORKDIR\nWORKDIR &#x2F;app\n切换目录（类似 cd）\n\n\nCOPY\nCOPY . .\n将当前目录复制到容器里\n\n\nRUN\nRUN npm install\n构建期间执行命令\n\n\nCMD\nCMD [“npm”, “start”]\n容器启动时运行（只能有一条）\n\n\nEXPOSE\nEXPOSE 3000\n说明服务监听的端口（仅文档提示）\n\n\n四、实战示例：Flask Web App📁 项目结构：\nmy-flask-app/├── app.py├── requirements.txt└── Dockerfile\n📄 app.py：\nfrom flask import Flaskapp = Flask(__name__)@app.route(&quot;/&quot;)def home():    return &quot;Hello,Docker!&quot;if __name__ == &quot;__main__&quot;:    app.run(host=&quot;0.0.0.0&quot;,port=5000)\n📄 requirements.txt：\nflask\n📄 Dockerfile：\nFROM python:3.9-slimWORKDIR /appCOPY ..RUN pip install -r requirements.txtEXPOSE 5000CMD [&quot;python&quot;,&quot;app.py&quot;]\n🛠 构建镜像并运行：\ndocker build -t my-flask-app .docker run -d -p 5000:5000 my-flask-app\n浏览器访问：http://localhost:5000🎉 成功！\n五、常见问题与技巧\n\n\n问题\n原因与解决方式\n\n\n\n容器运行后马上退出\nCMD 写错或服务没启动\n\n\n镜像太大\n换用 -slim、-alpine 镜像\n\n\n文件没拷进去\nCOPY 路径写错、.dockerignore 把它排除了\n\n\n构建慢\n用 .dockerignore 排除不必要的文件（比如 node_modules）\n\n\n六、Dockerfile 小技巧合集# 编译阶段FROM node:18 as buildWORKDIR /appCOPY ..RUN nom install &amp;&amp; npm run build# 部署阶段（nginx）FROM nginxCOPY --from=build /app/dist /usr/share/nginx/html#设置环境变量ENV PORT=8080\n最后送你一句口诀 🧠FROM 定基础，WORKDIR 定位置，COPY 拷代码，RUN 装环境，CMD 启动它。\nDocker Compose一、Docker Compose是什么？他是一个docker-compose.yml文件：    •\t描述多个服务（比如 web、db、redis）    •\t指定端口、挂载、网络、环境变量等    •\t一条命令就能启动：docker-compose up\n二、基本语法结构version: &#x27;3&#x27;    #Compose文件版本,一般用‘3’或‘3.8’services:       #定义所有容器服务    服务名1:        image: 镜像名 或 buld路径        ports:            - &quot;本地端口：容器端口&quot;        volumes:            - &quot;本地路径：容器路径&quot;        environment:            - &quot;变量名=值&quot;        depends_on:            - 其他服务名（启动顺序）    服务名2:        ....\n三、最简单示例：部署一个带自定义挂载的 Nginxmy-compose-project/├── docker-compose.yml├── html/│   └── index.html└── nginx.conf\n📄 docker-compose.yml 内容：\nversion: &#x27;3&#x27;services:  web:    image: nginx    ports:      - &quot;8080:80&quot;    volumes:      - ./html:/usr/share/nginx/html:ro      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n📌说明：    •\t端口映射：8080 → 容器内80    •\t挂载本地 .&#x2F;html 到 nginx 的网页根目录    •\t挂载本地配置文件替换默认 nginx 配置✅ 启动：\nUbuntudocker-compose up -d # 或者 docker compose up -d\n✅ 停止：\nUbuntudocker-compose down -v # 或者 docker compose down -v\n四、多服务组合示例（Node.js + MongoDB）version: &#x27;3&#x27;services:    app:        build: .        ports:            - &quot;3000:3000&quot;        environment:            - MONGO_URL=mongodb://mongo:27017/mydb        depends_on:            - mongo        mongo:        image: mongo        ports:            - &quot;27017:27017&quot;\n📌说明：    •\tapp 服务用 Dockerfile 构建    •\t依赖 Mongo 容器，并通过服务名 mongo 进行连接\n五、常见字段说明（适合记住）\n\n\n字段\n用法\n\n\n\nimage:\n使用已有镜像\n\n\nbuild:\n用 Dockerfile 构建镜像\n\n\nports:\n本地端口:容器端口\n\n\nvolumes:\n本地路径:容器路径\n\n\nenvironment:\n设置环境变量\n\n\ndepends_on:\n设置服务启动顺序\n\n\nrestart:\n容器崩溃时是否自动重启（如 always、on-failure）\n\n\nnetworks:\n设置自定义网络（可多个服务通信）\n\n\n六、实用命令大全Ubuntu# 启动服务docker-compose up -d # 或者 docker compose up -d# 停止并删除容器docker-compose down # 或者 docker compose down# 查看运行日志docker-compose logs # 或者 docker compose logs# 查看服务状态docker-compose ps # 或者 docker compose ps# 进入容器docker-compose exec 服务名 bash # 或者 docker compose exec 服务名 bash\n\n\n","categories":["服务端","docker"],"tags":["服务端","docker"]},{"title":"Prometheus+Grafana","url":"/2025/03/30/moniter/","content":"简介🔍 Prometheus 是什么？Prometheus 是一个“监控和数据采集系统”，简单理解就是一个“收集数据的仓库+大脑”。\n📦 它主要做这些事：    •\t采集数据：比如服务器的 CPU 使用率、内存占用、网络流量、请求次数等。    •\t存储数据：把这些数据以时间序列的形式存到自己的数据库里。    •\t查询数据：支持用专门的 PromQL 语言查询、筛选、聚合各种指标。    •\t设置告警：可以设置规则，当某个指标异常时触发告警（例如 CPU 连续5分钟超过 90%）。\n👀 简单说，它是“采集、存、查、报”的一套系统，不负责可视化。\n📊 Grafana 是什么？Grafana 是一个数据可视化工具，用来“把数据变成图表”。\n🎨 它主要做这些事：    •\t连接数据源：比如连接 Prometheus，读取里面的指标数据。    •\t绘制图表和仪表盘：你可以用它制作漂亮的图、线、饼图、热图等各种形式。    •\t设置仪表盘：将不同的数据组合成统一的监控面板，便于一眼看出系统健康状况。    •\t告警通知：Grafana 也支持设置告警（但数据还是从 Prometheus 来）。\n👀 简单说，它是“读数 + 画图 + 展示”的一套系统，不负责采集和存储。\n安装安装Node Exporter（监控服务器性能）Node Exporter是Prometheus的官方工具，可以帮助采集服务器的硬件指标（CPU、内存、磁盘等）。\nUbuntussh root@你的服务器ipsudo useradd --no-create-home --shell /bin/false node_exporter# 创建node_exporter用户(安全起见)wget https://github.com/prometheus/node_exporter/releases/download/v1.7.0/node_exporter-1.7.0.linux-amd64.tar.gztar xvf node_exporter-1.7.0.linux-amd64.tar.gzsudo cp node_exporter-1.7.0.linux-amd64/node_exporter /usr/local/bin/# 下载并解压node_exportersudo nano /etc/systemd/system/node_exporter.service# 设置systemd启动服务\n写入以下内容\nUbuntu[Unit]Description=Node ExporterAfter=network.target[Service]User=node_exporterExecStart=/usr/local/bin/node_exporter #文件路径[Install]WantedBy=default.target\n启动并设置开机启动\nUbuntusudo systemctl daemon-reexecsudo systemctl start node_exportersudo systemctl enable node_exporter\n测试一下：打开浏览器访问：http:&#x2F;&#x2F;你的服务器IP:9100&#x2F;metrics如果能看到一堆指标文字，说明成功！\n安装Prometheus下载Prometheus：\nUbuntuwget https://github.com/prometheus/prometheus/releases/download/v2.50.0/prometheus-2.50.0.linux-amd64.tar.gztar xvf prometheus-2.50.0.linux-amd64.tar.gz # 解压cd prometheus-2.50.0.linux-amd64 # 进入文件夹里面创建.yml文件nano prometheus.yml # 创建prometheus配置文件\n写入一下内容：\nglobal:         # 一定要写正确格式，包括空格以及重复定义  scrape_interval: 15sscrape_configs:  - job_name: &#x27;node_exporter&#x27;    static_configs: # 这个可能会有冲突       - targets: [&#x27;localhost:9100&#x27;]   - job_name: &#x27;website_http_check&#x27;    metrics_path: /probe    params:      module: [http_2xx]    static_configs:      - targets:          - http://你的域名或者IP  # 这里就是grafana的监控项          - prometheus:9090    relabel_configs:      - source_labels: [__address__]        target_label: __param_target      - source_labels: [__param_target]        target_label: instance      - target_label: __address__        replacement: localhost:9115  # blackbox_exporter 监听端口\n\n安装Blackbox Exporter(探测网站状态)Ubuntuwget https://github.com/prometheus/blackbox_exporter/releases/download/v0.25.0/blackbox_exporter-0.25.0.linux-amd64.tar.gztar xvf blackbox_exporter-0.25.0.linux-amd64.tar.gzcd blackbox_exporter-0.25.0.linux-amd64 ./blackbox_exporter     # 进入文件夹启动# 也可以添加systemd启动服务，和node_exporter类似。\n\n启动prometheusUbuntu./prometheus --config.file=prometheus.yml\n访问浏览器：http:&#x2F;&#x2F;你的服务器IP:9090，你应该可以看到 Prometheus 的 Web 页面。\n📊安装 Grafanasudo apt-get install -y apt-transport-https software-properties-common# 安装依赖 sudo apt-get install -y wgetwget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -echo &quot;deb https://packages.grafana.com/oss/deb stable main&quot; | sudo tee /etc/apt/sources.list.d/grafana.listsudo apt-get update# 添加grafana仓库sudo apt-get install grafanasudo systemctl start grafana-serversudo systemctl enable grafana-server# 安装并启动grafana\n访问grafana：浏览器打开 http:&#x2F;&#x2F;你的服务器IP:3000，默认账号密码是：用户名：admin密码：admin  登录之后会要求修改密码\n📈配置 Grafana添加数据源：选择 Prometheus，填入 http://localhost:9090导入 Dashboard 模板：Node Exporter：导入模板 ID 1860Blackbox 网站状态：导入模板 ID 7587\n使用grafana更改中文要将Grafana配置为中文，你可以参照以下步骤进行操作\n\n打开grafana的默认配置文件：&#x2F;opt&#x2F;bitnami&#x2F;grafana&#x2F;conf&#x2F;defaults.ini                   &#x2F;usr&#x2F;share&#x2F;grafana&#x2F;conf&#x2F;defaults.ini\n在该文件中，找到default_language这一行，将en-US改为zh-Hans。这样grafana的语言就会更改为中文。\n保存并关闭文件\n启服务刷新网页即可systemctl restart grafana-server\n\n监控告警🛠️ 设置 Prometheus 告警规则Prometheus 支持基于查询的告警规则，你可以通过 PromQL 设置条件，比如当系统负载过高时发出告警。\n\n创建告警规则文件在 Prometheus 配置目录下创建一个 alert.rules 文件（如果没有的话）：Ubuntunano /etc/prometheus/alert.rules # 看你prometheus安装/解压到了哪里\n在文件中加入告警规则，例如：groups:  - name: node_alerts    rules:    - alert: HighCPUUsage       expr: 100 * (1 - avg by (instance) (rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[1m]))) &gt; 80      for: 5m      labels:        severity: critical      annotations:        summary: &quot;CPU usage is above 80% on &#123;&#123; $labels.instance &#125;&#125;&quot;        description: &quot;CPU usage is above 80% for 5 minutes on &#123;&#123; $labels.instance &#125;&#125;.&quot;            - alert: HighLoadAverage      expr: node_load1 &gt; 2      for: 5m      labels:        severity: critical      annotations:        summary: &quot;High load average on &#123;&#123; $labels.instance &#125;&#125;&quot;        description: &quot;The 1-minute load average is above 2 on &#123;&#123; $labels.instance &#125;&#125;.&quot;\nHighCPUUsage：当 CPU 使用率超过 80% 持续 5 分钟时，触发告警。HighLoadAverage：当系统 1 分钟平均负载超过 2 时，触发告警。\n修改 Prometheus 配置文件，加载告警规则编辑 Prometheus 配置文件 prometheus.yml，加入规则文件：Ubunturule_files:  - &quot;/etc/prometheus/alert.rules&quot;\n重新启动 Prometheus\n\n修改完配置后，重新启动 Prometheus 服务来应用告警规则：\nsudo systemctl restart prometheus\n🛠️配置 Grafana 告警通知一旦 Prometheus 设置了告警规则，你就可以在 Grafana 中查看告警并设置通知。\n\n设置通知渠道\n\n首先需要在 Grafana 配置一个通知渠道，常用的有 邮件、钉钉、Slack 等。\n配置邮件通知    1.\t打开 Grafana UI，进入 “Alerting” &gt; “Notification channels”。    2.\t点击 “Add channel”。    3.\t选择通知方式（比如 Email）并填写相关信息：    •\tEmail Address：收件人邮箱    •\tSMTP：配置发送邮件的 SMTP 服务（如 Gmail 或自己配置的 SMTP）\n配置钉钉&#x2F;Slack 通知\n你可以选择使用钉钉或 Slack 的 Webhook，步骤类似，直接填写 Webhook URL。\n\n配置告警规则\n\n在 Grafana 中，进入你要监控的 Dashboard，并进行告警设置：    1.\t打开需要设置告警的图表，点击图表右上角的 “Alert” 标签。    2.\t配置告警条件，比如：    •\t当系统负载超过某个阈值。    •\t配置告警时间（比如 5 分钟内触发）。    3.\t在 “Notifications” 部分，选择之前配置好的通知渠道（比如 Email、钉钉等）。\n\n保存告警设置\n\n设置完成后，点击 “Save” 来保存告警规则。Grafana 会根据你设置的条件，定期检查，并在触发告警时通过邮件或钉钉等渠道发送通知。\n🧑‍💻验证告警是否有效\n要让 Grafana 能通过 SMTP 发送邮件告警通知，你需要配置它的 smtp 邮件发送服务。以Gmail为例\n\n\n\n\n配置项\n示例（以 Gmail 为例）\n\n\n\nSMTP 服务器地址\nsmtp.gmail.com\n\n\n端口号\n587 (TLS) &#x2F; 465 (SSL)\n\n\n发件邮箱\n&#x79;&#111;&#117;&#x72;&#x6e;&#x61;&#109;&#x65;&#x40;&#103;&#x6d;&#97;&#105;&#108;&#x2e;&#x63;&#111;&#x6d;\n\n\n发件邮箱密码\nGmail 生成的“应用专用密码”\n\n\n接收人邮箱\n任意你想收到告警的人邮箱地址\n\n\n\n修改 Grafana 配置文件 grafana.ini默认路径通常是：nano /etc/grafana/grafana.ini\n找到以下配置段落，把它修改成你的信息（注意取消注释）：#################################### SMTP / Emailing ##########################[smtp]enabled = truehost = smtp.gmail.com:587user = yourname@gmail.compassword = your_app_password   ; # Gmail 需要使用“应用专用密码”而不是登录密码;cert_file =;key_file =skip_verify = falsefrom_address = yourname@gmail.comfrom_name = Grafana Monitor[emails];welcome_email_on_sign_up = false\n💡如果你使用的是 QQ 邮箱、阿里邮箱、163 等都可以，改下 host、端口、密码即可\n🔐 关于 Gmail 的“应用专用密码”：\n   登录你的 Gmail 账号\n   打开： https://myaccount.google.com/security\n   开启 两步验证\n   找到“应用专用密码”，创建一个密码用于 Grafana 发送邮件\n   拷贝该密码，贴到上面 password 一栏中\n\n\n🔄重启 Grafana 服务配置改好之后需要重启 Grafana 才能生效：sudo systemctl restart grafana-server\n✉️在 Grafana 中测试发送邮件\n   登录 Grafana → 左侧点击 “Alerting” → “Contact points”\n   创建一个新的 Email 通知方式\n   输入你希望接收告警的邮箱地址\n   保存后点击 “Send test notification” 来验证是否能收到邮件\n\n\n\n✅ 如果设置成功，你应该会在邮箱里看到一个测试邮件！\n🎉 完成！\nDocker 部署我们如果要用docker部署的话 需要额外下载一个组件 “nginx-prometheus-exporter” 因为docker的容器有隔离机制 因此我们需要这个nginx容器暴露出来的 stub_status  页面\n\n\n\n组件名\n作用说明\n镜像名称（Docker Hub）\n备注\n\n\n\nPrometheus\n监控数据采集和存储\nprom&#x2F;prometheus\n采集 nginx-exporter、node-exporter、blackbox-exporter\n\n\nGrafana\n数据展示和可视化面板\ngrafana&#x2F;grafana\n连接 Prometheus 做图表\n\n\nnginx-prometheus-exporter\n抓取 Nginx 的内部状态指标\nnginx&#x2F;nginx-prometheus-exporter\n需要 Nginx 开启 stub_status\n\n\nnode-exporter\n抓取服务器本身 CPU、内存、磁盘、网络指标\nprom&#x2F;node-exporter\n服务器基础性能监控\n\n\nblackbox-exporter\n外部探测 HTTP&#x2F;HTTPS 可用性、状态等\nprom&#x2F;blackbox-exporter\n检测网站存活、SSL证书有效期等\n\n\nNginx（你的Web服务器）\n提供网站服务+反向代理\nnginx:latest\n被监控的对象\n\n\nDocker Compose的配置方法\nPrometheusdocker-compose的配置方法\nservices:    prometheus:      image: prom/prometheus      container_name: prometheus      ports:        - &quot;9090:9090&quot;      volumes:        - &quot;./prometheus.yml:/etc/prometheus/prometheus.yml&quot;      restart: always\nGrafanadocker-compose的配置方法\nservices:    grafana:      image: grafana/grafana      container_name: grafana      ports:        - &quot;3000:3000&quot;      restart: always      environment:        - GF_SERVER_ROOT_URL=https://yourServername/grafana/\nnginx-prometheus-exporter 暴露容器内部docker-compose的配置方法。\nnginx-exporter:      image: nginx/nginx-prometheus-exporter      container_name: nginx-exporter      ports:        - &quot;9113:9113&quot;      command:#        - nginx.scrape-uri=http://nginx/stub_status        - &quot;--nginx.scrape-uri=https://yourServername/stub_status&quot; # 如果你的网站没有ssl证书 改成http即可#        - &quot;--nginx.ssl-verify=false&quot;      depends_on:        - nginx      restart: always\n\nnode-exporter 监控服务器性能docker-compose的配置方法。\nservices:   nodexport:      image: prom/node-exporter      container_name: exporter      ports:        - &quot;9100:9100&quot;      restart: always\nblackbox-exporter 监控网站状态docker-compose的配置方法\nservices:    blackbox-exporter:      image: prom/blackbox-exporter:latest      container_name: blackbox-exporter      ports:        - &quot;9115:9115&quot;      restart: always\n\n","categories":["运维","监控","Prometheus+Grafana"],"tags":["运维","监控"]},{"title":"DevOps 世界的灵魂技术：CI/CD 流水线","url":"/2025/04/13/CI-CD/","content":"DevOps 世界的灵魂技术：CI&#x2F;CD 流水线\n什么是 CI&#x2F;CD 流水线CI&#x2F;CD &#x3D; 持续集成 + 持续交付 &#x2F; 持续部署是一整套“自动化流水线”，用来让软件开发从提交代码 → 自动构建 → 自动测试 → 自动部署，一条龙完成\nCI&#x2F;CD 是干嘛的你写代码 → 推送到 GitHub / GitLab           ↓      ✅ CI 阶段（持续集成）      - 自动编译打包      - 自动跑单元测试      - 自动代码检查           ↓      🚀 CD 阶段（持续交付 / 部署）      - 自动构建 Docker 镜像      - 自动发布到测试 / 生产环境      - 自动通知（钉钉 / Slack）\nCI&#x2F;CD 各阶段都干了啥？\n\n\n阶段\n中文名\n做什么举动？\n\n\n\nCI（持续集成）\nContinuous Integration\n自动测试 + 打包构建\n\n\nCD（持续交付）\nContinuous Delivery\n自动发布到测试环境，人工确认上线\n\n\nCD（持续部署）\nContinuous Deployment\n自动发布到生产环境，无人工干预\n\n\n典型的流水线长这样\n\n# Gitlab CI 示例 .gitlab-ci.ymlstages:    - build    - test    - deploybuild:    stage: build    script:        - npm install         - npm run build    artifacts:        path:            - dist/test:    stage: test    script:        - npm testdeploy:    stage: deploy    script:        - docker build -t my-app .        - docker push myregistry.com/my-app        - ssh deploy@server &#x27;docker pull my-app &amp;&amp; docker restart my-app&#x27;\n🛠 常用 CI&#x2F;CD 工具平台有哪些？\n\n\n工具\n说明\n推荐指数\n\n\n\nGitHub Actions\nGitHub 原生支持，简单易上手\n⭐⭐⭐⭐⭐\n\n\nGitLab CI&#x2F;CD\nGitLab 自带 CI&#x2F;CD，集成度高\n⭐⭐⭐⭐\n\n\nJenkins\n开源界老牌 CI&#x2F;CD 工具\n⭐⭐⭐⭐（适合自定义复杂流程）\n\n\nGitea + Drone\n私有部署组合\n⭐⭐⭐\n\n\nCircleCI &#x2F; Travis CI\n国外流行，GitHub 项目多\n⭐⭐⭐（限免费额度）\n\n\n💡 现实例子：部署一个 Vue 项目 + 后端服务\n\n\n开发人员提交代码到 GitHub\nGitHub Actions 自动触发：•\t运行测试•\t执行构建（npm run build）•\t打包为 Docker 镜像•\t推送到 Docker Hub &#x2F; 私有仓库•\tSSH 登录服务器远程部署 &#x2F; 使用 K8s 滚动更新•\t通知钉钉 &#x2F; 邮件群“部署完成”\n\n🎉 全程不用你手点，自动完成\nCI&#x2F;CD 的价值总结\n\n\n好处\n描述\n\n\n\n🧹 降低人为错误\n减少部署出错、环境不一致等问题\n\n\n🚀 加快迭代速度\n提交代码后几分钟就能上线\n\n\n📦 提高质量\n每次提交都跑测试，代码更稳定\n\n\n🤝 提升团队协作\n所有人按统一标准部署，不容易混乱\n\n\n🔄 易于回滚\n版本打包有记录，可随时切回\n\n\n使用以此博客作为实战项目。使用GitHub Actions作为流水线工具🔧\n\n目标是什么？实现一件事：我改完博客内容，push 到 GitHub，服务器自动更新上线，不用我点压缩、FTP！\n目前的工具组合\n\n\n\n\n工具\n用法\n说明\n\n\n\nGitHub + GitHub Actions\n托管代码 + 执行 CI&#x2F;CD 流水线\n免费、好用\n\n\nSSH + rsync\n自动远程上传代码\n替代 FTP，更快更稳\n\n\nNginx\n你已经部署好了，用作 Web 服务\n根目录挂载网站内容\n\n\n使用 Jenkins下载 jenkis💡 Jenkins 安装位置建议\n\n\n\n安装位置\n适合人群\n优点\n缺点\n\n\n\n✅ 本地开发机\n开发者、测试者、博客站点维护者\n安装简单，易调试，不涉及公网安全问题\n电脑关机就不能自动部署了，不能远程持续运行\n\n\n✅ 云服务器\n想让 Jenkins 24小时在线自动部署\n持久在线，适合多人协作\n安装和配置略复杂，要注意安全（如开放 8080 端口、权限管理）\n\n\nMac本地安装Jenkins（最简单方式）\n使用 Homebrew 安装 Jenkinsbrew install jenkins-lts # 下载jenkinsbrew services start jenkins-lts # 启动jenkins\n默认 Jenkins 会跑在 http://localhost:8080 上，你可以直接用浏览器打开它。\n输入管理员密码（第一次登录）页面标题是：Unlock Jenkins（解锁 Jenkins）第一次打开 Jenkins 会让你输入密码，你可以运行cat /Users/你的用户名/.jenkins/secrets/initialAdminPassword# jenkins界面会有提示\n复制输出的那串密码，粘贴回 Jenkins 页面里，点【继续】。\n安装插件系统会问你： •\t【安装推荐的插件】（Install suggested plugins）✅ 推荐选择这个 •\t【选择插件要安装】（Select plugins to install）🔘 请点击第一个【安装推荐插件】，它会自动安装常用插件（比如 Git、SSH、Pipeline 等）。💡 提示：这个过程需要几分钟时间。耐心等待插件安装完毕。\n创建第一个管理员用户安装插件后，它会进入这个页面，让你创建一个账户： •\t用户名（Username）: 你自己定义一个 •\t密码（Password）: 自己设 •\t完整名称（Full name）: 随意填写 •\t邮箱地址（Email address）: 推荐填真实邮箱填好后点击【保存并继续（Save and Continue）】。\n配置 Jenkins URL系统会提示你默认访问地址，例如：http://localhost:8080保持默认，点击【保存并完成（Save and Finish）】。\n\n创建Pipeline项目\n我们来到jenkins的web主界面，点击左上角的 Jenkins，即可到达首页\n点击【新建任务】（New Item）\n输入任务名称，例如：deploy-hexo-blog\n选择类型：【流水线（Pipeline）】✅\n点击【确定】\n在 Pipeline 页面中配置到最下面的 “流水线（Pipeline）” 区块，（推荐在vscode中编写好Jenkinsfile之后复制到这里）\n   定义方式：选择【Pipeline script】\n   在“Script”框中粘贴以下内容（我们先用最基础的版本）\n\n\n\npipeline &#123;    agent any    environment &#123;        DEPLOY_SERVER = &#x27;你的服务器ip&#x27;        DEPLOY_USER = &#x27;root&#x27;    // 你服务器的用户        DEPLOY_PATH =  &#x27;/var/www/html&#x27;   // 你要上传到的目录        SSH_CREDENTIALS_ID = &#x27;ecs-ssh&#x27;   // 凭证        LOCAL_HEXO_DIR = &#x27;/Users/macos/Desktop/blog&#x27;  // 本地的目录(绝对路径)    &#125;    stages &#123;        stage(&#x27;压缩public文件夹&#x27;)&#123;            steps &#123;                sh &quot;&quot;&quot;                    cd $&#123;env.LOCAL_HEXO_DIR&#125;                    zip -r ../public.zip ./public                &quot;&quot;&quot;            &#125;        &#125;        stage(&#x27;删除之前的public文件夹&#x27;)&#123;            steps &#123;                script &#123;                    sshagent (credentials: [&quot;$&#123;env.SSH_CREDENTIALS_ID&#125;&quot;]) &#123;                        sh &quot;&quot;&quot;                            ssh $&#123;DEPLOY_USER&#125;@$&#123;DEPLOY_SERVER&#125; &#x27;cd $&#123;DEPLOY_PATH&#125; &amp;&amp; rm -rf public&#x27;                        &quot;&quot;&quot;                    &#125;                &#125;            &#125;        &#125;        stage(&#x27;上传并部署&#x27;)&#123;            steps &#123;                script &#123;                    sshagent (credentials: [&quot;$&#123;env.SSH_CREDENTIALS_ID&#125;&quot;]) &#123;                        sh &quot;&quot;&quot;                            scp $&#123;env.LOCAL_HEXO_DIR&#125;/../public.zip $&#123;DEPLOY_USER&#125;@$&#123;DEPLOY_SERVER&#125;:$&#123;DEPLOY_PATH&#125;/                            ssh $&#123;DEPLOY_USER&#125;@$&#123;DEPLOY_SERVER&#125; &#x27;cd $&#123;DEPLOY_PATH&#125; &amp;&amp; unzip -o public.zip &amp;&amp; rm -f public.zip&#x27;                            ssh $&#123;DEPLOY_USER&#125;@$&#123;DEPLOY_SERVER&#125; &#x27;cd $&#123;DEPLOY_PATH&#125; &amp;&amp; chmod -R 755 public&#x27;                        &quot;&quot;&quot;                    &#125;                &#125;            &#125;        &#125;    &#125;&#125;\n\n点击页面底部的【保存】按钮\n\n运行部署任务！\n   回到项目页面，点击左侧【立即构建（Build Now）】\n   Jenkins 会开始执行：•\t压缩你本地的public文件夹•\t通过 SSH 登录到 ECS 删除之前的public文件夹•\t上传文件到你的部署目录\n   点击左侧【构建历史】中的蓝色小球 → 查看【控制台输出（Console Output）】✅ 如果看到 Finished: SUCCESS 就说明部署成功啦！\n\n设置凭证刚才我们设置了 SSH_CREDENTIALS_ID 由于我们是刚刚创建好的jenkins还没有配置凭证\n[ssh-agent] Could not find specified credentials: ecs-ssh\n🔍 Jenkins 报错：找不到名为 ecs-ssh 的凭据\n添加 SSH 凭据并命名为 ecs-ssh🔧 步骤如下：    1.\t打开 Jenkins 主界面    2.\t点击左侧【凭据（Credentials）】    •\t如果你找不到这个入口，也可以通过：    •\t【Manage Jenkins】→【Security】或【Manage Credentials】    3.\t选择：(global) 全局作用域    4.\t点击左边【Add Credentials】（添加凭据）📝 添加 SSH 凭据填写内容如下：\n使用 Github Actions目录结构如果没有workflows 需要手动创建！\n我的博客/├── .github/│   └── workflows/│       └── deploy.yml      👈 GitHub Actions 流水线脚本│   └── dependabot.yml      ├── public/                 👈 构建后输出目录├── package.json / config.yml\nGitHub Actions自动部署脚本name: 自动部署博客到服务器on:    push:        branches:            - main  # 使用的分支，如果是master 修改这里jobs:    deploy:        runs-on: ubuntu-latest        steps:            - name: 拉代码              uses: actions/checkout@v3            - name: 安装Node.js               uses: actions/setup-node@v3              with:                node-version: 18                               - name: 安装依赖 &amp; 构建博客               run: |                npm install                 npm install -g hexo-cli                npx hexo generate            # 如果只需要上传资源到服务器 可以省去安装node 和hexo的依赖            - name: 上传到服务器              uses: easingthemes/ssh-deploy@v2.1.5              with:                SSH_PRIVATE_KEY: $&#123;&#123; secrets.SERVER_SSH_KEY &#125;&#125;                REMOTE_USER: root   # 你的服务器用户名                REMOTE_HOST: x.x.x.x    # 你的服务器IP                TARGET: /var/www/html   # 你nginx的根目录 写到根上一个文件夹                SOURCE: public/         # 你网页的资源                \n配置服务器 SSH 密钥\n在本地执行命令生成密钥：ssh-keygen -t rsa -b 4096 -C &quot;you@example.com&quot;\n拷贝公钥到服务器：ssh-copy-id your_user@your.server.ip\n或者手动把 ～&#x2F;.ssh&#x2F;id_rsa.pub的内容追加到服务器的：~/.ssh/authorized_keys\n把私钥~&#x2F;.ssh&#x2F;id_rsa 的内容复制，粘贴到 GitHub 仓库中：GitHub → Settings → Secrets → Actions → New repository secret名字叫：SERVER_SSH_KEY值是你私钥的内容（注意安全，不要泄露）\n\n修改 REMOTE_USER、REMOTE_HOST、TARGET比如你服务器用户名是 root，公网 IP 是 1.2.3.4，部署路径是 &#x2F;var&#x2F;www&#x2F;html，那你就填\nREMOTE_USER: rootREMOTE_HOST: 1.2.3.4TARGET: /var/www/html\n最后 推送试试！git add .git commit -m &quot;首次添加自动部署&quot;git push origin main\n🌟 然后进入 GitHub → Actions，就能看到它自动执行！\n部署成功后，你就可以访问 http:&#x2F;&#x2F; your.server.ip 查看效果！💡 小建议：可选加一行日志打印\n- name: 查看构建结果文件夹  run: ls -al public/ \n"},{"title":"Kubernetes / K8s","url":"/2025/04/13/Kubernetes/","content":"简介Kubernetes（简称 K8s）是 Google 开源的容器编排平台，它的核心能力是：\n自动管理大规模容器：运行、扩容、重启、故障转移、服务发现等\n它的目标是：“你只管说‘我需要几个服务’，K8s 来帮你部署、分配、调度、维护”。\n开始前\n学习 Kubernetes 前你需要会的\n\n\n\n\n必备知识\n状态\n\n\n\nLinux 基本操作\n✅\n\n\nDocker（容器镜像、run、volume）\n✅\n\n\nCI&#x2F;CD 简单概念\n✅\n\n\nNginx、Web 服务部署\n✅\n\n\nYAML 配置文件\n✅\n\n\n🥇 入门阶段：了解核心概念（可以 2 小时搞懂）\n\n\n\n核心概念\n简单理解\n\n\n\nPod\n容器的最小运行单位，1~n 个容器组成\n\n\nNode\n工作节点（本质就是服务器）\n\n\nDeployment\n声明你要运行哪些 Pod、多少个副本、怎么升级\n\n\nService\n网络服务，提供访问入口（ClusterIP &#x2F; NodePort）\n\n\nNamespace\n项目隔离空间（类似 Git 分支）\n\n\n🥈 实操阶段：本地部署 K8s，跑个服务\n\n\n\n方法\n推荐工具\n\n\n\n本地单节点测试\nminikube ✅ 推荐（轻量 + 官方）\n\n\nDocker Desktop 内置 K8s\n✅ Mac 用户也适合\n\n\n使用 kubectl 控制集群\n必备 CLI 工具\n\n\n跑一个 Nginx\n创建 Deployment + Service\n\n\n跑你自己的博客镜像\n比如用你已有的静态 HTML 做一个 nginx 容器跑起来\n\n\n🥉 进阶阶段：部署 + 高可用 + CI&#x2F;CD 集成\n\n\n\n技术点\n应用\n\n\n\nHelm\nK8s 的 “包管理器”，一键部署 WordPress &#x2F; Redis &#x2F; MySQL\n\n\nIngress\nHTTP 代理路由入口，比如实现 blog.karen.com\n\n\nConfigMap + Secret\n配置注入（如博客 config）\n\n\nKustomize\n多环境配置管理\n\n\nGitOps\nCI&#x2F;CD 自动部署到 K8s（ArgoCD、Flux）\n\n\nPrometheus + Grafana\n集群监控可视化\n\n\nCluster 集群\n一句话理解什么是“集群”（Cluster）集群 &#x3D; 一组“联网协作的服务器”，它们对外表现成“一个整体”来提供服务。❓集群是不同地区的主机吗？不一定。集群可以在同一机房，也可以跨地区，只要网络能通就可以形成集群。但大多数企业为了性能，会把集群部署在同一个局域网 &#x2F; 数据中心里（比如阿里云、K8s 云服务集群）❓集群是“一个服务用一群主机来跑”吗？ ✅ 正解！ 你可以： •\t把一个服务部署到多个节点上，分摊压力（比如你的博客 + 负载均衡） •\t把多个服务（博客、评论、数据库）部署到同一个集群，资源复用 Kubernetes 会自动决定： •\t哪台机器资源够？就分配上去 •\t哪个服务需要 3 个副本？我自动帮你部署到 3 台节点 •\t哪个节点宕机？自动重启到别的节点上！\n\n📦 类比解释一：集群就像一个“厨房团队”\n\n\n•\t你想点一份“大餐服务”（比如部署你博客 + 数据库 +评论系统）•\t一个厨师（单台服务器）可能忙不过来•\t所以你请了一整组厨师（多台机器）•\t厨房团队（集群）会自动决定：•\t谁煮主菜？•\t谁负责炒菜？•\t万一一个厨师倒下（宕机），谁来顶上？\n✅ 这整个厨房团队 &#x3D; “集群”✅ 他们之间的分工、调度、故障切换 &#x3D; Kubernetes 来负责\n\n📌 技术一点说：\n\n\n\n\n名称\n含义\n\n\n\n集群 (Cluster)\n一组通过网络连接的“节点”服务器\n\n\n节点 (Node)\n集群中的一台机器，可以是虚拟机或物理机\n\n\n主节点 (Master)\n管理整个集群的大脑，负责调度、监控、API\n\n\n工作节点 (Worker)\n实际跑你应用的机器（比如跑 nginx &#x2F; 博客）\n\n\nk8s中的“集群结构图”            [ Master 控制节点 ]           ┌───────────────┐           │  调度服务 kube-scheduler           │  API Server           │  状态控制器           └───────────────┘                     ↓      ┌──────────────┬──────────────┐      ↓              ↓              ↓[Worker Node1]   [Worker Node2]  [Worker Node3]  └─Pod: Nginx     └─Pod: Blog     └─Pod: Redis  └─Pod: Mongo     └─Pod: Hexo     └─Pod: 评论系统\n现实中的“集群”都用在哪？\n\n\n\n场景\n应用\n\n\n\n大公司网站\n多地部署，形成全球K8s集群(CDN+服务节点)\n\n\n企业SaaS平台\n用集群提升高可用性+自动扩容能力\n\n\n云服务商\n用户只用申请一个“集群”，背后全自动   ｜\n\n\n集群是多台主机组成的“一个大脑 + 多个手”的团队。K8s 负责调度大脑，让每个服务都能稳定运行，掉了就补、慢了就扩。k8s解决了什么问题？你用 Docker 启动了一个 Web 服务：\ndocker run -d -p 80:80 my-app\n很好用没错。但是后来你发现问题越来越多；    1.\t要部署 10 个容器怎么办？怎么管理？    2.\t容器挂了怎么办？手动重启太麻烦。    3.\t多个服务器如何分配资源？怎么调度？    4.\t配置、密钥、服务发现怎么统一管理？    5.\t如何升级不影响用户？如何快速回滚？🎯 这些痛点就是 Kubernetes 诞生的原因：它是为了解决大规模容器管理、自动化调度和高可用性问题而生的。\n必须知道的核心概念\n\n\n概念\n小白理解方式\n\n\n\nPod\n是 K8s 中的最小 “部署单位”，通常一个 Pod 包含一个容器，就像一个房间住一个人\n\n\nNode\n运行 Pod 的主机，可以是真实机器或虚拟机\n\n\nCluster\n多个 Node 组成一个 K8s 集群\n\n\nDeployment\n定义一组 Pod 怎么创建、升级、回滚，保持数量稳定\n\n\nService\n为一组 Pod 提供统一访问入口，类似 “前台服务台”\n\n\nNamespace\n相当于集群里的分区，用于资源隔离（比如测试环境和生产环境）\n\n\nIngress\n让外部可以通过域名访问集群内服务\n\n\nVolume &#x2F; PVC\n给容器挂载数据盘，让数据不会因容器消失而丢失\n\n\nConfigMap &#x2F; Secret\n存配置文件和密码的地方，避免硬编码进镜像\n\n\nRBAC 权限控制\n限制谁能做什么操作，防止权限过大出问题\n\n\nKubelet &#x2F; Controller &#x2F; Scheduler\n是 K8s 的“大脑和神经系统”，自动完成任务调度和容器生命周期管理\n\n\n必须知道的容器概念\n\n\n概念\n简要说明\n\n\n\n镜像 (Image)\n是程序 + 环境的打包文件，相当于 App 安装包\n\n\n容器 (Container)\n是运行中的镜像，是进程不是虚拟机\n\n\nDocker\n是最常用的容器引擎，K8s 用它（或 containerd）运行容器\n\n\n容器编排\n多个容器如何自动部署、扩容、重启，就是 K8s 做的事\n\n\nYAML 配置\nK8s 所有资源都靠 YAML 定义，需要能看懂基本结构\n\n\n安装K8s 生产环境在安装 Kubernetes（特别是用 kubeadm 搭建生产级多节点集群）之前，确实需要做一系列“打地基”的设置，不然后续很容易出现各种诡异问题（如 kubelet 启动失败、网络不通、无法加入集群等）。\n前提一、系统基础配置（所有节点都需要）\n\n\n设置项\n建议值&#x2F;动作\n说明\n\n\n\n操作系统\nUbuntu 20.04+ &#x2F; CentOS 7+\n兼容最好，建议使用 LTS 版本\n\n\n用户权限\n使用 root 用户 或 sudo 权限用户\n所有设置都需要管理员权限\n\n\n主机名唯一\nhostnamectl set-hostname node1\n否则可能无法区分节点\n\n\nhosts 配置\n每个节点要能解析其他节点名\n修改 /etc/hosts 加入节点映射\n\n\n时间同步\n安装 chrony 或 ntp 保证时间一致\n时间不一致会导致证书验证失败\n\n\n二、关闭或配置系统功能（重要！）\n\n\n项目\n命令\n原因\n\n\n\n关闭 swap\nswapoff -a 并注释 /etc/fstab 中 swap 行\nKubernetes 禁止使用 swap\n\n\n关闭防火墙（开发环境）\nsystemctl stop firewalld/ufw\n节点间通讯可能被拦截，生产环境要配置策略\n\n\n关闭 SELinux（CentOS）\nsetenforce 0 并编辑 /etc/selinux/config\n否则 kubelet 启动失败\n\n\n配置 iptables\nmodprobe br_netfilter + 设置 sysctl 参数\n否则网络插件会出问题\n\n\ncat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.confbr_netfilterEOFcat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables  = 1net.ipv4.ip_forward                 = 1net.bridge.bridge-nf-call-ip6tables = 1EOFsysctl --system\n三、容器运行时选择因为k8s在1.24版本弃用了docker的支持 所以更支持用containerd来跑容器\n\n\n\n选项\n说明\n\n\n\ncontainerd ✅\n官方推荐，轻量稳定\n\n\nDocker ❌\n已不推荐，需额外安装 cri-dockerd\n\n\n推荐安装 containerd：\nsudo apt install -y containerdsudo mkdir -p /etc/containerdcontainerd config default | sudo tee /etc/containerd/config.tomlsudo systemctl restart containerd\n四、安装 kubeadm &#x2F; kubelet &#x2F; kubectl（核心三件套）添加 K8s 官方源 + 安装：\nsudo apt update &amp;&amp; sudo apt install -y apt-transport-https curlcurl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.listdeb https://apt.kubernetes.io/ kubernetes-xenial mainEOFsudo apt updatesudo apt install -y kubelet kubeadm kubectlsudo apt-mark hold kubelet kubeadm kubectl\n\n安装 k8s这次我们采用的单节点\ncrictl 和 nerdctl你在 crictl 中能看到 nginx:latest 等镜像但在 nerdctl images 里是空的说明你的镜像目前只存在于 containerd 的默认 namespace（k8s.io）中，而 nerdctl 默认使用的是 moby namespace。✅ 解决方案：切换 nerdctl 的 namespace使用以下命令查看 containerd 中有哪些命名空间：\nctr namespaces list\n你大概率会看到像这样的一些 namespace：\nNAME     LABELSdefaultk8s.iomoby\n➤ 查看 k8s.io 中的镜像：\nnerdctl --namespace k8s.io images\n✅ 如果你想导出这些镜像例如导出 nginx：\nnerdctl --namespace k8s.io save nginx:latest -o /tmp/nginx.tar\n然后在 moby 或其他你打算用来构建的 namespace 中导入：\nnerdctl --namespace moby load -i /tmp/nginx.tar\n📌 你可以设置默认 namespace（可选）如果你想让 nerdctl 默认也用 k8s.io 的镜像，可以设置：\nexport CONTAINERD_NAMESPACE=k8s.io\n加进 .bashrc 或 .zshrc 里就能永久生效。操作目的命令示例查看镜像在哪些 namespace 下ctr namespaces listnerdctl 查看 k8s 镜像nerdctl –namespace k8s.io images导出 nginx 镜像nerdctl –namespace k8s.io save nginx -o nginx.tar导入镜像到默认环境nerdctl load -i nginx.tar\nnerdctl –namespace k8s.io images –digests\nnerdctl –namespace k8s.io image prune\n安装K8S 内网生产环境准备工作机器数量3个，采用1master+2node的架构部署集群\n\n\n\nIP\n主机名\n角色\n数量\n配置\n\n\n\n192.168.6.235\nk8s-master\nmaster\n1\n16C 32G\n\n\n192.168.7.75\nk8s-node1\nnode\n1\n16C 32G\n\n\n192.168.7.76\nk8s-node2\nnode\n1\n16C 32G\n\n\n部署 K8S\n更改主机名 配置yum源按照上述，更改主机名hostnamectl set-h^Ctname k8s-masterhostnamectl set-h^Ctname k8s-node1hostnamectl set-h^Ctname k8s-node2# 注意按照相应的版本调整阿里云的源地址wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo\n配置hosts文件192.168.6.235 k8s-master192.168.7.75 k8s-node1192.168.7.76 k8s-node2\n关闭防火墙# 临时关闭sudo setenforce 0# 永久禁用sudo sed -i &#x27;s/^SELINUX=.*/SELINUX=disabled/&#x27; /etc/selinux/configsudo systemctl stop firewalldsudo systemctl disable firewalld\n禁用swap分区# 临时关闭；关闭swapsudo swapoff -a# 永久关闭sudo sed -i &#x27;/swap/d&#x27; /etc/fstab# 可以通过这个命令查看swap是否关闭了free\n安装必要模块\n\nyum install  -y ipvsadm ipset sysstat conntrack libseccomp# dummy0网卡和kube-ipvs0网卡：在安装k8s集群时，启用了ipvs的话，就会有这两个网卡。（将service的IP绑定在kube-ipvs0网卡上）cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashipvs_modules=&quot;ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack ip_tables ip_set xt_set ipt_set ipt_rpfilter ipt_REJECT ipip &quot;for kernel_module in \\$&#123;ipvs_modules&#125;; do  /sbin/modinfo -F filename \\$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1  if [ $? -eq 0 ]; then    /sbin/modprobe \\$&#123;kernel_module&#125;  fidoneEOFchmod 755 /etc/sysconfig/modules/ipvs.modules sh /etc/sysconfig/modules/ipvs.modules lsmod | grep ip_vs# 转发 IPv4 并让 iptables 看到桥接流量cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.confoverlaybr_netfilterEOFsudo modprobe overlaysudo modprobe br_netfilter# 设置所需的 sysctl 参数，参数在重新启动后保持不变cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables  = 1net.bridge.bridge-nf-call-ip6tables = 1net.ipv4.ip_forward                 = 1EOF# 应用 sysctl 参数而不重新启动sudo sysctl --system# 检查是否安装正确lsmod | grep br_netfilterlsmod | grep overlay# 确认 net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables 和 net.ipv4.ip_forward 系统变量在你的 sysctl 配置中被设置为 1sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward\n\n运行时，选择 containerd# 可以直接安装yum install -y containerd# 下载安装包，然后解压即可https://github.com/containerd/containerd/blob/main/docs/getting-started.md\n配置containerd，镜像加速，cgroup等# 查看containerd版本containerd --version版本为 1.6.32# 配置为aliyun的镜像源mkdir /etc/containerdcontainerd config default &gt; /etc/containerd/config.tomlsed -i &quot;s#registry.k8s.io/pause:3.8#registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.9#g&quot;  /etc/containerd/config.toml# 配置镜像加速vim /etc/containerd/config.toml  [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors]    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]      endpoint = [&quot;https://docker-mirror.h3d.com.cn&quot;]# 配置cgroupvim /etc/containerd/config.toml[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]  SystemdCgroup = true\n配置k8s源\n\ncat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF\n\n安装kubelet、kubeadm、kubectl(所有节点都需要)\n\n# 查看可用版本yum list kubelet --showduplicates |grep 1.28# 安装yum install -y kubelet-1.28.2 kubeadm-1.28.2 kubectl-1.28.2 --disableexcludes=kubernetessystemctl enable --now kubelet\n\n配置crictl(如果想要在所有节点操作，可以都安装)\n\n# 如果每个节点都需要crictl，可以安装并配置cat  &lt;&lt;EOF | sudo tee /etc/crictl.yamlruntime-endpoint: unix:///var/run/containerd/containerd.socktimeout: 5image-endpoint: unix:///var/run/containerd/containerd.sockEOF\n\n初始化(仅在master节点操作)\n\nkubeadm init --kubernetes-version=1.28.15 \\--apiserver-advertise-address=193.168.6.235  \\--image-repository  registry.aliyuncs.com/google_containers \\--pod-network-cidr=10.1.0.0/16--service-cidr=10.96.0.0/12\n输出如下\nYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user:  mkdir -p $HOME/.kube  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run:  export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:  https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.6.235:6443 --token r10sv8.8wdmesq0hl16ztxy \\    --discovery-token-ca-cert-hash sha256:fdcbd538e705dd0d68ea7d0aea289f09d1b3e461bab539c2f0b4262ae36762b9 \n\n按照初始化输出，进行操作，并添加master污点\n\nmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configexport KUBECONFIG=/etc/kubernetes/admin.conf# 添加污点，避免业务进程调度到master节点kubectl taint nodes --all node-role.kubernetes.io/control-plane-\n\n检查集群状态\n\nkubectl get nodeskubectl get pods -A\n\n安装网络插件\n\nkubectl apply -f scripts/calico.yaml\n\n\n检查集群并添加worker节点\n\n# 所有worker节点上执行kubeadm join 192.168.6.235:6443 --token r10sv8.8wdmesq0hl16ztxy \\    --discovery-token-ca-cert-hash sha256:fdcbd538e705dd0d68ea7d0aea289f09d1b3e461bab539c2f0b4262ae36762b9 # 查看node状态kubectl get nodes\n\n\n\n\n\n安装K8s nimikube 学习测试版本curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64sudo install minikube-linux-amd64 /usr/local/bin/minikube# x86架构 是amd64  如果是arm架构的需要换成 arm64minikube start --driver=docker # 如果到这步卡住 是因为网络问题拉不到镜像 # 可以换下面的方法minikube start \\  --image-mirror-country=cn \\  --registry-mirror=https://registry.cn-hangzhou.aliyuncs.com \\  --driver=docker# 如果还不可以 那我们就用docker去拉镜像 然后在minikube的启动参数上添加 --base-image=镜像名# --base-image=registry.cn-hangzhou.aliyuncs.com/google_containers/kicbase:v0.0.46\n不知道自己是什么CPU架构？\nuname -m# aarch64   aarch64就是arm架构\nkubectl get ns local-path-storage -o json | jq ‘del(.spec.finalizers)’| kubectl replace –raw “&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;local-path-storage&#x2F;finalize” -f -\nK8s命令🧭 集群与上下文管理\n\n\n操作\n命令\n\n\n\n查看集群信息\nkubectl cluster-info\n\n\n查看当前上下文\nkubectl config current-context\n\n\n查看所有上下文\nkubectl config get-contexts\n\n\n切换上下文\nkubectl config use-context &lt;context-name&gt;\n\n\n设置默认命名空间\nkubectl config set-context --current --namespace=&lt;namespace&gt;\n\n\n📦 资源管理（Pod、Deployment、Service）\n\n\n操作\n命令\n\n\n\n查看所有资源\nkubectl get all\n\n\n查看所有 Pod\nkubectl get pods [-n &lt;namespace&gt;] [-o wide]\n\n\n查看 Deployment\nkubectl get deployments\n\n\n查看 Service\nkubectl get svc\n\n\n创建资源\nkubectl apply -f &lt;file.yaml&gt;\n\n\n删除资源\nkubectl delete -f &lt;file.yaml&gt;\n\n\n删除 Pod\nkubectl delete pod &lt;pod-name&gt;\n\n\n滚动重启 Deployment\nkubectl rollout restart deployment &lt;deployment-name&gt;\n\n\n修改资源配置\nkubectl edit deployment &lt;deployment-name&gt;\n\n\n🔍 查看与调试\n\n\n操作\n命令\n\n\n\n查看日志\nkubectl logs &lt;pod-name&gt;\n\n\n实时查看日志\nkubectl logs -f &lt;pod-name&gt;\n\n\n查看容器日志\nkubectl logs &lt;pod-name&gt; -c &lt;container-name&gt;\n\n\n进入容器终端\nkubectl exec -it &lt;pod-name&gt; -- /bin/bash\n\n\n查看 Pod 信息\nkubectl describe pod &lt;pod-name&gt;\n\n\n查看集群事件\nkubectl get events\n\n\n🧱 命名空间管理\n\n\n操作\n命令\n\n\n\n查看命名空间\nkubectl get namespaces\n\n\n创建命名空间\nkubectl create namespace &lt;name&gt;\n\n\n删除命名空间\nkubectl delete namespace &lt;name&gt;\n\n\n💾 存储管理（PVC、PV）\n\n\n操作\n命令\n\n\n\n查看 PVC\nkubectl get pvc\n\n\n查看 PV\nkubectl get pv\n\n\n🛠 配置管理（ConfigMap、Secret）\n\n\n操作\n命令\n\n\n\n创建 ConfigMap\nkubectl create configmap &lt;name&gt; --from-literal=key=value\n\n\n查看 ConfigMap\nkubectl get configmap\n\n\n创建 Secret\nkubectl create secret generic &lt;name&gt; --from-literal=key=value\n\n\n查看 Secret\nkubectl get secrets\n\n\n📈 网络与服务（Service、Ingress）\n\n\n操作\n命令\n\n\n\n创建 Deployment\nkubectl create deployment &lt;name&gt; --image=&lt;image&gt;\n\n\n创建 Service\nkubectl expose deployment &lt;name&gt; --port=80 --target-port=8080 --type=NodePort\n\n\n查看 Ingress\nkubectl get ingress\n\n\n🧪 临时调试与导出\n\n\n操作\n命令\n\n\n\n临时启动容器\nkubectl run -it --rm debug --image=busybox -- /bin/sh\n\n\n导出资源为 YAML\nkubectl get deployment &lt;name&gt; -o yaml &gt; deployment.yaml\n\n\n","categories":["运维","k8s"],"tags":["运维","k8s"]},{"title":"Ansible","url":"/2025/04/23/Ansible/","content":"Ansible 是一个自动化运维工具，可以帮你用“一段脚本”自动做一堆服务器上的重复工作，比如：装软件、改配置、重启服务、部署项目……你可以把它理解成：“我把要做的事情写进一本‘剧本’，Ansible 来帮我远程在服务器上一步步执行。\n简介🔑 Ansible 的工作机制（一句话总结）：你写好要做的事情（Playbook） → Ansible 用 SSH 连接到你的服务器 → 按步骤一条条执行任务。🧱 Ansible 的基础组成部分：\n\nInventory（清单）🗂️告诉 Ansible 要连接哪些服务器，用什么方式连接。[webservers]192.168.1.10192.168.1.11[db]127.0.0.1 ansible_connection=local\nModules（模块）🧩 Ansible 提供的功能小工具，比如“安装软件”、“创建文件”、“启动服务”等等，都是模块完成的。\n\n\n\n\n模块\n用途\n\n\n\napt&#x2F;yum\n查看网络\n\n\ncopy&#x2F;template\n创建网络\n\n\nservice\n查看网络详情\n\n\nuser\n将容器加入某个网络\n\n\ncommand&#x2F;shell\n启动时指定网络\n\n\n\nPlaybook（剧本）📜你写的一份 .yaml 文件，定义了“在哪些机器上执行哪些任务”。- hosts: all  become: yes  tasks:    - name: 安装nginx      apt:        name: nginx        state: present\nTasks(任务)🧾Playbook 中的每一个动作，比如“安装 nginx”、“复制文件”，都叫一个任务（task）。\nVariables（变量）📦你可以给一些值起名字，方便复用。比如：vars:  nginx_port:8080\nRoles（角色）📁让你的项目结构更清晰，比如专门搞一个 “nginx” 的文件夹，里面是安装、配置、重启 nginx 的所有内容。\n\n💡 Ansible 跟 Shell 脚本的区别？\n\n\n项目\nShell 脚本\nAnsible\n\n\n\n写法\nBash 命令串\nYAML 写的任务清单\n\n\n可读性\n一般\n很高，易读\n\n\n复用性\n差\n好，支持变量和模块\n\n\n错误处理\n要手写判断\n自动判断执行结果\n\n\n多机部署\n要循环 + 远程命令\n天生多机执行（Inventory 配置即可）\n\n\n使用Ansible\n🧾 第一步：准备你的 Ansible 主机清单（Inventory）创建一个hosts.ini的文件：[all]192.168.1.101192.168.1.102192.168.1.103192.168.1.104\n📌 说明：这里定义了一个叫 webservers 的组，包含3台要删除 Nginx 的服务器 IP。你可以换成你自己的服务器地址。\n🛠️ 第二步：写一个下载 Nginx 的 Playbook创建一个名为 install_nginx.yml 的 YAML 文件：- name: install nginx  # 此任务名称  hosts: all        # 这里的all指向的是hosts文件中的[all]  become: yes       # 使用 sudo 权限执行  tasks:      # 下面要执行的具体任务列表    - name: install nginx    # 第一个任务 安装 nginx      apt:      # 使用 apt 模块        name: nginx     # 要安装的软件包名: nginx        state: present    # 保证软件包“已安装”状态（不存在就会被安装）        update_cache: yes     # 更新 apt 源缓存    - name: start nginx      # 第二个任务 启动 nginx      service:   # 使用 service模块操作系统服务        name: nginx     # 操作的服务名称: nginx        state: started    # 保证服务处于 “启动”状态        enabled: yes      #设置为开机自启\n▶️ 第三步：运行这个 Playbook 命令ansible-playbook -i ../hosts install_nginx.yml \n\n实战批量安装 Kubernetes\n第一步 先创建inventorymkdir -p ~/k8scd k8snano hosts.ini\n编写hosts文件[all]172.17.50.246 ansible_user=h3d ansible_become=true ansible_become_method=sudo172.17.50.247 ansible_user=h3d ansible_become=true ansible_become_method=sudo172.17.50.248 ansible_user=h3d ansible_become=true ansible_become_method=sudo172.17.50.249 ansible_user=h3d ansible_become=true ansible_become_method=sudo[master]172.17.50.246[worker]172.17.50.247172.17.50.248172.17.50.249\n\n设置基础环境用ansible来批量设置master和worker的环境\n\n创建playbooknano setup.yml\n- name: base environment (shuting swap)  hosts: all  become: yes  tasks:    - name: shuting swap      shell: swapoff -a      ignore_errors: true    - name: permenant shuting swap      replace:        path: /etc/fstab        regexp: &#x27;^\\s*(.+?\\s+)+swap\\s+&#x27;        replace: &#x27;# \\1&#x27;      ignore_errors: true    - name: enable kernel module      shell: |        modprobe overlay        modprobe br_netfilter      ignore_errors: true    - name: deploy kernel arguments      copy:        dest: /etc/sysctl.d/k8s.conf        content: |          net.bridge.bridge-nf-call-ip6tables = 1          net.bridge.bridge-nf-call-iptables = 1    - name: apply sysctl configration      shell: sysctl --system\n\n容器选择因为k8s在1.24版本移除了docker的支持，因此我们推荐使用containerd来座位k8s的容器，具体为什么我们移步 K8s 章节观看\n\n创建playbooknano install-containerd.yml\n\n- name: install containerd  hosts: all  become: yes  tasks:    - name: install containerd      apt:        name: containerd        state: present        update_cache: yes    - name: make containerd configuration file      file:        path: /etc/containerd        state: directory    - name: create default configuration file      shell: containerd config default &gt; /etc/containerd/config.toml      args:        creates: /etc/contaierd/config.toml    - name: enable SystemdCgroup (compatable kubernetes)      replace:        path: /etc/containerd/config.toml        regexp: &#x27;SystemdCgroup = false&#x27;        replace: &#x27;SystemdCgroup = true&#x27;    - name: restart &amp;&amp; enable containerd service      systemd:        name: containerd        enabled: yes        state: restarted\n我们在主节点生成配置文件\ncontainerd config default &gt; /etc/containerd/config.toml\n找到这个位置，确认存在并设置为阿里云镜像：\n[plugins.&quot;io.containerd.grpc.v1.cri&quot;]  sandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.8&quot;\n向下继续找到 runc 配置段，设置如下（一定要加上 SystemdCgroup &#x3D; true）：\n[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]  SystemdCgroup = true\n安装k8s\n创建playbooknano install-k8s.yml\n写入以下配置- name: install kubernetes module  hosts: all  become: yes  tasks:    - name: add Kubernetes source      copy:        dest: /etc/apt/sources.list.d/kubernetes.list        content: |          deb [trusted=yes] https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main    - name: update apt source      apt:        update_cache: yes    - name: install kueblet kubeadm kubectl      apt:        name:          - kubelet          - kubeadm          - kubectl        state: present        update_cache: yes    - name: lock version      shell: apt-mark hold kubelet kubeadm kubectl\n运行ansible-playbook -i ../hosts install-k8s.yml --ask-pass --ask-become-pass\n\n","categories":["运维","Ansible"],"tags":["运维","Ansible"]},{"title":"Docker/Kubernetes内网生产环境导致镜像无法拉取","url":"/2025/05/24/issuer/","content":"docker因为墙的问题很好解决，这篇主要是关于企业内网自建1.24版本之后的k8s集群，containerd无法拉取镜像的问题。\nDocker由于2024年6月开始国内的大量docker镜像停服😤，Docker无法下载安装镜像无法拉取😭 详情我在docker篇已经写过。这里就不再赘述。\nK8s Containerd的运行时下由于k8s在1.24版本弃用了docker的支持 所以更支持用containerd来跑容器，可是在我们在创建pod以及各种组件containerd都会默认去从dockerhub去拉取镜像，在这里不论我去containerd的config.toml文件下添加镜像源也不管事儿，拉取镜像都是失败。所以我直接用梯子的方式给我的内网集群都添加上了代理。\n可是在添加上全局代理之后，我的k8s还是拉不到镜像， 因为Kubernetes 的容器拉取行为由 容器运行时（如 containerd、Docker） 执行，它们运行在系统服务中，并 不继承你 shell 中的代理环境变量（如 ALL_PROXY）。由于我的代理是用shadowsocks协议 是另一台海外的服务器自建的vpn隧道，我直接在本地的各个节点下载好客户端就行。接下来 我们开启完整的操作步骤 让你的内网自建k8s集群也能轻松访问外网拉取到镜像。\n第一步：在公司服务器上安装 shadowsocks-libev（作为客户端）\nsudo apt updatesudo apt install shadowsocks-libev -y# centos 就替换成 yum\n第二步：配置 Shadowsocks 客户端\nsudo nano /etc/shadowsocks-libev/config.json\n填入如下内容(改成你自己的)：\n&#123;    &quot;server&quot;:&quot;123.123.123.123&quot;,        // 你香港ECS的公网IP    &quot;server_port&quot;:8388,                // SS端口    &quot;local_port&quot;:1080,                 // 本地监听端口（默认1080）    &quot;password&quot;:&quot;your_password&quot;,        // SS密码    &quot;timeout&quot;:300,    &quot;method&quot;:&quot;aes-256-gcm&quot;,            // 加密方式，需与你的SS服务端一致    &quot;fast_open&quot;: false&#125;\n第三步：启动 Shadowsocks 客户端\nsudo systemctl restart shadowsocks-libev-localsudo systemctl enable shadowsocks-libev-local\n如果显示notfound话 那就代表没有守护进程 这里我们需要配置下守护进程\n\n我们用的是 ss-local 命令（客户端，绑定本地 127.0.0.1:1080）which ss-local /usr/bin/ss-local   # 复制这个# 如果找不到，请先安装sudo apt install shadowsocks-libev\n创建 systemd 服务文件：sudo nano /etc/systemd/system/ss-local.service\n填入以下内容（注意配置文件路径与你实际一致）：[Unit]Description=Shadowsocks Local Client ServiceAfter=network.target[Service]ExecStart=/usr/bin/ss-local -c /etc/shadowsocks-libev/config.jsonRestart=on-failure[Install]WantedBy=multi-user.target\n如果 ss-local 路径不是 &#x2F;usr&#x2F;bin&#x2F;ss-local，请用 which ss-local 替换它。\n重新加载 systemd 并启动服务：sudo systemctl daemon-reexecsudo systemctl daemon-reloadsudo systemctl start ss-local.servicesudo systemctl enable ss-local.service# 查看状态确认是否启动成功sudo systemctl status ss-local.service\n✅ 启动成功后，你的本地 127.0.0.1:1080 就可以作为 socks5 代理使用了：curl --socks5-hostname 127.0.0.1:1080 https://google.com\n🧪 附：测试 IP 是否成功通过代理curl --socks5-hostname 127.0.0.1:1080 cip.cc\n第四步：使用 Privoxy 转换 SOCKS5 → HTTP这里你会发现containerd还是拉取不了镜像，这里我们就需要一个Privoxy工具将SOCKS5→HTTP\n\n安装并配置privoxy\nsudo apt install privoxy -y# 配置 Privoxy 将 HTTP 请求转发给 ss-local 的 SOCKS5 端口sudo nano /etc/privoxy/config\n添加一行（放到文件最后）：\nforward-socks5t / 127.0.0.1:1080 . \n启动并检查端口监听\nsudo systemctl restart privoxysudo systemctl enable privoxy# 检查监听：ss -tuln | grep 8118# 你应该能看到：127.0.0.1:8118\n第五步：为容器运行时配置代理\n\n创建或编辑代理配置文件（containerd 使用 systemd 启动）：sudo mkdir -p /etc/systemd/system/containerd.service.dsudo nano /etc/systemd/system/containerd.service.d/http-proxy.conf\n内容如下（请改为你实际使用的代理端口）：[Service]Environment=&quot;HTTP_PROXY=http://127.0.0.1:8118&quot;Environment=&quot;HTTPS_PROXY=http://127.0.0.1:8118&quot;Environment=&quot;NO_PROXY=127.0.0.1,localhost,10.0.0.0/8,192.168.0.0/16&quot;\n🧠 注意：•\tcontainerd 不能直接识别 SOCKS5，所以需要用一个额外的本地 HTTP 代理转接 SOCKS5，或者让 ss-local 启动一个 http-local 端口\n\n这样我们就可以直接用containerd来拉取镜像了！\n"}]